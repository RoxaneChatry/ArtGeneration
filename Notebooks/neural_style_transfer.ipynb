{"cells":[{"cell_type":"markdown","metadata":{"id":"iMVX3ZEDE9GM"},"source":["# Neural style transfer\n","\n","Transfert de style d'une image à une autre\n","\n","A utiliser pour appliquer un style d'une image sur le tableau créé. \n"]},{"cell_type":"markdown","metadata":{"id":"0fYHYZZqE9GU"},"source":["## Introduction\n","\n","Style transfer consists in generating an image\n","with the same \"content\" as a base image, but with the\n","\"style\" of a different picture (typically artistic).\n","This is achieved through the optimization of a loss function\n","that has 3 components: \"style loss\", \"content loss\",\n","and \"total variation loss\":\n","\n","- The total variation loss imposes local spatial continuity between\n","the pixels of the combination image, giving it visual coherence.\n","- The style loss is where the deep learning keeps in --that one is defined\n","using a deep convolutional neural network. Precisely, it consists in a sum of\n","L2 distances between the Gram matrices of the representations of\n","the base image and the style reference image, extracted from\n","different layers of a convnet (trained on ImageNet). The general idea\n","is to capture color/texture information at different spatial\n","scales (fairly large scales --defined by the depth of the layer considered).\n","- The content loss is a L2 distance between the features of the base\n","image (extracted from a deep layer) and the features of the combination image,\n","keeping the generated image close enough to the original one.\n","\n","**Reference:** [A Neural Algorithm of Artistic Style](\n","  http://arxiv.org/abs/1508.06576)\n"]},{"cell_type":"markdown","metadata":{"id":"YWUCvA9xE9GW"},"source":["## Setup\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"SaeNR47zHoL3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647349513853,"user_tz":-60,"elapsed":552153,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}},"outputId":"9372e6f3-b66b-4c30-b4c6-9f7a719f5b8d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tu8NjWNdE9GY","executionInfo":{"status":"ok","timestamp":1647349517190,"user_tz":-60,"elapsed":3361,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.applications import vgg19\n","import matplotlib.pyplot as plt\n","from skimage.io import imread\n","from IPython.display import Image, display\n","\n","result_path = \"/content/drive/Shareddrives/PFE artists/Roxane/\"\n"]},{"cell_type":"markdown","metadata":{"id":"AKRvZAZUE9Gd"},"source":["## Image preprocessing / deprocessing utilities\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"AofoqY4eE9Ge","executionInfo":{"status":"ok","timestamp":1647349517470,"user_tz":-60,"elapsed":34,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["def get_dim(content_image_path):\n","  # Récupère les dimensions de l'image cible (longueur set et largeur proportionnelle)\n","  width, height = keras.preprocessing.image.load_img(content_image_path).size\n","  img_nrows = 400\n","  img_ncols = int(width * img_nrows / height)\n","  return img_nrows, img_ncols\n","\n","\n","def preprocess_image(image_path):\n","    # Util function to open, resize and format pictures into appropriate tensors\n","    img = keras.preprocessing.image.load_img(\n","        image_path, target_size=target_size\n","    )\n","    img = keras.preprocessing.image.img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    img = vgg19.preprocess_input(img)\n","    return tf.convert_to_tensor(img)\n","\n","\n","def deprocess_image(x):\n","    # Util function to convert a tensor into a valid image\n","    x = x.reshape((*target_size, 3))\n","    # Remove zero-center by mean pixel\n","    x[:, :, 0] += 103.939\n","    x[:, :, 1] += 116.779\n","    x[:, :, 2] += 123.68\n","    # 'BGR'->'RGB'\n","    x = x[:, :, ::-1]\n","    x = np.clip(x, 0, 255).astype(\"uint8\")\n","    return x\n","\n"]},{"cell_type":"markdown","metadata":{"id":"i0o0-0V2E9Gf"},"source":["## Compute the style transfer loss\n","\n","First, we need to define 4 utility functions:\n","\n","- `gram_matrix` (used to compute the style loss)\n","- The `style_loss` function, which keeps the generated image close to the local textures\n","of the style reference image\n","- The `content_loss` function, which keeps the high-level representation of the\n","generated image close to that of the base image\n","- The `total_variation_loss` function, a regularization loss which keeps the generated\n","image locally-coherent\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"9cJalKtqE9Gh","executionInfo":{"status":"ok","timestamp":1647349517473,"user_tz":-60,"elapsed":32,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["# The gram matrix of an image tensor (feature-wise outer product)\n","def gram_matrix(x):\n","    x = tf.transpose(x, (2, 0, 1))\n","    features = tf.reshape(x, (tf.shape(x)[0], -1))\n","    gram = tf.matmul(features, tf.transpose(features))\n","    return gram\n","\n","\n","# The \"style loss\" is designed to maintain\n","# the style of the reference image in the generated image.\n","# It is based on the gram matrices (which capture style) of\n","# feature maps from the style reference image\n","# and from the generated image\n","def style_loss(style, result):\n","    S = gram_matrix(style)\n","    C = gram_matrix(result)\n","    channels = 3\n","    size = target_size[0]*target_size[1]\n","    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n","\n","\n","# An auxiliary loss function\n","# designed to maintain the \"content\" of the\n","# base image in the generated image\n","def content_loss(content, result):\n","    return tf.reduce_sum(tf.square(result - content))\n","\n","\n","# The 3rd loss function, total variation loss,\n","# designed to keep the generated image locally coherent\n","def total_variation_loss(x):\n","  nrows, ncols = target_size\n","  a = tf.square(\n","    x[:, : nrows - 1, : ncols - 1, :] - x[:, 1:, : ncols - 1, :]\n","  )\n","  b = tf.square(\n","    x[:, : nrows - 1, : ncols - 1, :] - x[:, : nrows - 1, 1:, :]\n","  )\n","  return tf.reduce_sum(tf.pow(a + b, 1.25))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"e3qGjgJ_E9Gi"},"source":[" ## Création du modèle"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Ma7urIrwE9Gj","executionInfo":{"status":"ok","timestamp":1647349518431,"user_tz":-60,"elapsed":984,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d71cd4fa-c43e-4f22-ce58-0d8b12807d18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 0s 0us/step\n","80150528/80134624 [==============================] - 0s 0us/step\n"]}],"source":["# Build a VGG19 model loaded with pre-trained ImageNet weights\n","model = vgg19.VGG19(weights=\"imagenet\", include_top=False)\n","\n","# Get the symbolic outputs of each \"key\" layer (we gave them unique names).\n","outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n","\n","# Set up a model that returns the activation values for every layer in VGG19 (as a dict).\n","feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)\n"]},{"cell_type":"markdown","metadata":{"id":"HKktTMKEE9Gk"},"source":["Finally, here's the code that computes the style transfer loss.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"jtkd855CE9Gk","executionInfo":{"status":"ok","timestamp":1647349518434,"user_tz":-60,"elapsed":16,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["# List of layers to use for the style loss.\n","style_layer_names = [\n","    \"block1_conv1\",\n","    \"block2_conv1\",\n","    \"block3_conv1\",\n","    \"block4_conv1\",\n","    \"block5_conv1\",\n","]\n","# The layer to use for the content loss.\n","content_layer_name = \"block5_conv2\"\n","\n","\n","def compute_loss(result_image, content_image, style_image, weights):\n","    content_weight, style_weight, total_variation_weight = weights\n","    input_tensor = tf.concat(\n","        [content_image, style_image, result_image], axis=0\n","    )\n","    features = feature_extractor(input_tensor)\n","\n","    # Initialize the loss\n","    loss = tf.zeros(shape=())\n","\n","    # Add content loss\n","    layer_features = features[content_layer_name]\n","    content_image_features = layer_features[0, :, :, :]\n","    combination_features = layer_features[2, :, :, :]\n","    loss = loss + content_weight * content_loss(\n","        content_image_features, combination_features\n","    )\n","    # Add style loss\n","    for layer_name in style_layer_names:\n","        layer_features = features[layer_name]\n","        style_reference_features = layer_features[1, :, :, :]\n","        combination_features = layer_features[2, :, :, :]\n","        sl = style_loss(style_reference_features, combination_features)\n","        loss += (style_weight / len(style_layer_names)) * sl\n","\n","    # Add total variation loss\n","    loss += total_variation_weight * total_variation_loss(result_image)\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"k3CklWPpE9Gl"},"source":["## Add a tf.function decorator to loss & gradient computation\n","\n","To compile it, and thus make it fast.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"hAMUNy61E9Gn","executionInfo":{"status":"ok","timestamp":1647349518680,"user_tz":-60,"elapsed":258,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["\n","@tf.function\n","def compute_loss_and_grads(result_image, content_image, style_image, weights):\n","    with tf.GradientTape() as tape:\n","        loss = compute_loss(result_image, content_image, style_image, weights)\n","    grads = tape.gradient(loss, result_image)\n","    return loss, grads\n","\n"]},{"cell_type":"markdown","metadata":{"id":"8xWGysYqE9Go"},"source":["## The training loop\n","\n","Repeatedly run vanilla gradient descent steps to minimize the loss, and save the\n","resulting image every 100 iterations.\n","\n","We decay the learning rate by 0.96 every 100 steps.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"okBlTqfXE9Gq","executionInfo":{"status":"ok","timestamp":1647349518683,"user_tz":-60,"elapsed":26,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["def train(content_image, style_image, result_path, result_image, optimizer, weights, epochs, nb_saves=100, verbose=True):\n","  \"\"\" entrainement du réseau sur les images données\n","\n","  params:\n","    content_image : image dont le contenu sera utilisé\n","    style_image : image dont le style sera utilisé\n","    result_path : chemin où sauvegarder les résultats successifs\n","    result_image : contient\n","    nb_saves : nombre de sauvegardes d'images à faire au long de l'entrainement\n","    verbose : indique s'il faut afficher les détails de l'entrainement\n","  \"\"\"\n","\n","  save_rate = int(epochs/nb_saves) if nb_saves !=0 else epochs\n","  history = []\n","\n","  for i in range(1, epochs + 1):\n","    loss, grads = compute_loss_and_grads(\n","        result_image, content_image, style_image, weights\n","    )\n","    optimizer.apply_gradients([(grads, result_image)])\n","    # enregistrement de la loss\n","    history.append(loss)\n","    if i % save_rate == 0:\n","      if verbose:\n","        print(\"Iteration %d: loss=%.2f\" % (i, loss))\n","      img = deprocess_image(result_image.numpy())\n","      fname = result_path + \"_at_iteration_%d.png\" % i\n","      keras.preprocessing.image.save_img(fname, img)\n","  # fin de l'entrainement\n","  print(\"--- \\nFin de l'entrainemnt : loss finale = %.2f\"%loss)\n","  img = deprocess_image(result_image.numpy())\n","  fname = result_path + \"_at_iteration_%d.png\" % i\n","  keras.preprocessing.image.save_img(fname, img)\n","  return history\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"icDlmUeOF9HZ","executionInfo":{"status":"ok","timestamp":1647349518685,"user_tz":-60,"elapsed":25,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["# fonction principale : \n","def main(content_image_path, style_image_path, result_img_path, epochs=100, saves=10, weights=(2.5e-10, 1e-6, 1e-6), affichage=False):\n","  # Poids des composants de la loss (à optimiser)\n","  # total_variation_weight = 1e-6\n","  # style_weight = 1e-6\n","  # content_weight = 2.5e-8\n","  # weights = (content_weight, style_weight, total_variation_weight)\n","\n","  optimizer = keras.optimizers.SGD(\n","    keras.optimizers.schedules.ExponentialDecay(\n","        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96\n","    )\n","  )\n","\n","  global target_size\n","  target_size = get_dim(content_image_path)\n","\n","  content_image = preprocess_image(content_image_path)\n","  style_image = preprocess_image(style_image_path)\n","  result_image = tf.Variable(preprocess_image(content_image_path))\n","\n","  history = train(\n","      content_image, \n","      style_image, \n","      result_img_path, \n","      result_image, \n","      optimizer, \n","      weights, \n","      epochs, \n","      nb_saves=saves, \n","      verbose=affichage\n","      )\n","  \n","  # affichage des résultats\n","  if affichage:\n","    figure, axs = plt.subplots(nrows=1,ncols=3,figsize=(15,5) )\n","    axs[0].imshow(imread(content_image_path))\n","    plt.title(\"Image de contenu\")\n","    axs[1].imshow(imread(style_image_path))\n","    plt.title(\"Image de style\")\n","    axs[2].imshow(imread(result_img_path + \"_at_iteration_%d.png\" % epochs))\n","    plt.title(\"Résultat\")\n","    plt.show()\n","\n","    plt.figure()\n","    plt.title(\"évolution de la loss le long des epochs\")\n","    plt.plot(history)\n","    plt.show()\n","\n","  return history"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"jgzI-BWeJkFy","colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"status":"error","timestamp":1647350007966,"user_tz":-60,"elapsed":489302,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}},"outputId":"b11d4bca-0c50-4cbf-ef2d-99a8c59b068f"},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-299c63d8a107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcontent_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/Shareddrives/PFE artists/data/wikiart/base/Photo/ffcf64f150.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstyle_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/Shareddrives/PFE artists/data/wikiart/base/Cubism/victor-brauner_dobrudjan-landscape-1937.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_image_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"test2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffichage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-b5fcc78be16c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(content_image_path, style_image_path, result_img_path, epochs, saves, weights, affichage)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mnb_saves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaves\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maffichage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m       )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-1cf195b3b9b3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(content_image, style_image, result_path, result_image, optimizer, weights, epochs, nb_saves, verbose)\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     loss, grads = compute_loss_and_grads(\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mresult_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     )\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# premier test avec 2 images\n","content_image_path = \"/content/drive/Shareddrives/PFE artists/data/wikiart/base/Photo/ffcf64f150.jpg\"\n","style_image_path = \"/content/drive/Shareddrives/PFE artists/data/wikiart/base/Cubism/victor-brauner_dobrudjan-landscape-1937.jpg\"\n","h = main(content_image_path, style_image_path, result_path+\"test2\", epochs=50, saves=0, affichage=True)\n","print(h.numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"udEV7GmkE9Gr","executionInfo":{"status":"aborted","timestamp":1647350007956,"user_tz":-60,"elapsed":41,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["style = \"/content/drive/Shareddrives/PFE artists/data/wikiart/base/Symbolism/zinaida-serebriakova_mountain-landscape-switzerland-1914.jpg\"\n","content = \"/content/drive/Shareddrives/PFE artists/data/wikiart/base/Photo/fffc0836d7.jpg\"\n","# h = main(content, style, result_path+\"test3\", epochs=200, saves=5, affichage=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ECyS6VVUboYH","executionInfo":{"status":"aborted","timestamp":1647350007960,"user_tz":-60,"elapsed":38,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["style = \"/content/drive/Shareddrives/PFE artists/data/wikiart/extended/Pointillism/theo-van-rysselberghe_pines-and-eucalyptus-at-cavelieri-1905.jpg\"\n","content = \"/content/drive/Shareddrives/PFE artists/data/wikiart/extended/Impressionism/zinaida-serebriakova_pond-in-tsarskoe-selo-1913.jpg\"\n","# test dans un sens puis dans l'autre\n","#main(content, style, result_path+\"test4\", epochs=100, saves=0, affichage=True)\n","#main(style, content, result_path+\"test5\", epochs=100, saves=0, affichage=True)"]},{"cell_type":"markdown","metadata":{"id":"6G9AEYFra-pr"},"source":["# Etude de l'influence des poids appliqués aux différents losses\n","\n","objectif : minimiser le temps d'entrainement nécessaire à la convergence\n","variables :\n","\n","\n","*   ordre de grandeur des 3 poids\n","*   rapport content/style\n","*   rapport content/total\n","\n","\n","\n","---\n","\n","comment caractériser la convergence ? \n","limite basse sur la pente ? \n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-IFAdoUSFDA","executionInfo":{"status":"aborted","timestamp":1647350007961,"user_tz":-60,"elapsed":38,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["def find_convergence(history, inter=1000):\n","  # détermine l'époch à partir duquel l'amélioration (diminution) de la loss est considérée comme négligeable\n","  res = -1\n","  i=1\n","  eps = history[0]/inter\n","  while res<0 and i<len(history):\n","    test = abs(history[i] - history[i-1])\n","    if test < eps:\n","      res = i\n","    i+=1\n","  return (res if res>0 else len(history)+1)\n","\n","def test(ordre_de_grandeur, content_style, content_total, inter=1000):\n","  style = \"/content/drive/Shareddrives/PFE artists/data/wikiart/extended/Pointillism/theo-van-rysselberghe_pines-and-eucalyptus-at-cavelieri-1905.jpg\"\n","  content = \"/content/drive/Shareddrives/PFE artists/data/wikiart/extended/Impressionism/zinaida-serebriakova_pond-in-tsarskoe-selo-1913.jpg\"\n","\n","  # teste toutes les combinaisons \n","  Lord = len(ordre_de_grandeur)\n","  Lcs = len(content_style)\n","  Lct = len(content_total)\n","  #tab = np.zeros((Lord, Lcs, Lct))\n","\n","  # ord0 = 1e-6\n","  cs0 = 2.5e-2\n","  ct0 = 2.5e-2\n","  # INITIALISATION\n","  # total_variation_weight = 1e-6\n","  # style_weight = 1e-6\n","  # content_weight = 2.5e-8\n","\n","  # 1- Optimisation de l'ordre de grandeur\n","  # ct et cs restent fixés\n","  tab = np.zeros(Lord)\n","  for ord in range(Lord):\n","    w_total = ordre_de_grandeur[ord]\n","    w_content = w_total * ct0\n","    w_style = w_content / cs0\n","    weights = (w_content, w_style, w_total)\n","    hist = main(content, style, result_path, epochs=100, saves=0, weights=weights)\n","    tab[ord] = find_convergence(hist, inter=inter)\n","  print(\"Optimisation de l'ordre de grandeur\\n\", tab)\n","  best_ordi = np.where(tab == tab.min())\n","  print(best_ordi)\n","  print(best_ordi[0])\n","  best_ord = ordre_de_grandeur[int(best_ordi[0][0])]\n","  print(\"Ordre de grandeur optimal : \", best_ord)\n","\n","  # 2- optimisation de content_style\n","  tab = np.zeros(Lcs)\n","  for cs in range(Lcs):\n","    w_total = best_ord\n","    w_content = w_total * ct0\n","    w_style = w_content / content_style[cs]\n","    weights = (w_content, w_style, w_total)\n","    hist = main(content, style, result_path, epochs=100, saves=0, weights=weights)\n","    tab[cs] = find_convergence(hist, inter=inter)\n","  print(\"Optimisation du rapport content/style \\n\", tab)\n","  best_csi = np.where(tab == tab.min())\n","  print(best_csi)\n","  print(best_csi[0][0])\n","  best_cs = ordre_de_grandeur[int(best_csi[0][0])]\n","  print(\"Content / style optimal : \", best_cs)\n","\n","  # 3- optimisation de content_total\n","  tab = np.zeros(Lct)\n","  for ct in range(Lct):\n","    w_total = best_ord\n","    w_content = w_total * content_total[ct]\n","    w_style = w_content / best_cs\n","    weights = (w_content, w_style, w_total)\n","    hist = main(content, style, result_path, epochs=100, saves=0, weights=weights)\n","    tab[ct] = find_convergence(hist, inter=inter)\n","  print(\"Optimisation du rapport content/ total \\n\", tab)\n","  best_cti = np.where(tab == tab.min())\n","  print(best_cti)\n","  print(best_cti[0][0])\n","  best_ct = ordre_de_grandeur[int(best_cti[0][0])]\n","  print(\"Content / total optimal : \", best_ct)\n","\n","  # CONCLUSION\n","  w_total = best_ord\n","  w_content = w_total * best_ct\n","  w_style = w_content / best_cs\n","  best_weights = (w_content, w_style, w_total)\n","  return best_weights\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4pTv5KfPiV9Q","executionInfo":{"status":"aborted","timestamp":1647350007964,"user_tz":-60,"elapsed":39,"user":{"displayName":"Roxane Chatry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14146719894395936762"}}},"outputs":[],"source":["# range de valeurs à tester\n","ordre_de_grandeur = [1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11]  #[1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11] \n","content_style = [0.01, 0.1, 1, 10, 100]\n","content_total = [0.01, 0.1, 1, 10, 100]\n","\n","w = test(ordre_de_grandeur, content_style, content_total, 7000)\n","#w = test([1e-6], [1e-1, 1e-2], [1e-1, 1e-2])\n","print(w)"]},{"cell_type":"markdown","source":["# resultats\n","\n","+ avec inter=1000 : (1e-14, 1e-9, 1e-9)\n","\n","\n","# idées :\n","\n","\n","*   créer d'autres losses pour évaluer la qualité du tableau produit\n","\n","*   Créer une fonction qui évalue la luminosité / le contraste du tableau pour vérifier qu'il est \"visible\"\n","\n","*   Tester d'autres modèles de machine learning ? \n","\n","\n","*   Créer une fonction qui évalue si le style d'un tableau est assez marqué pour être utilisé dans un transfert \n","\n"],"metadata":{"id":"tKSnk3ccJ1Pb"}}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"neural_style_transfer","provenance":[{"file_id":"https://github.com/keras-team/keras-io/blob/master/examples/generative/ipynb/neural_style_transfer.ipynb","timestamp":1645628193274}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"}},"nbformat":4,"nbformat_minor":0}